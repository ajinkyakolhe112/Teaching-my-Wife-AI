# 0 to LLM Workshop

This workshop is designed to take you from zero to understanding and working with Large Language Models (LLMs). The workshop consists of 16 lectures, with the first 6 lectures covering fundamental concepts and practical implementations.

## Concepts & Skills to learn Roadmap
- [ ] Using LLM (AIStudio, NotebookLM, Jules & misc - ChatGPT, )
- [ ] Introduction to DL Neural Network 
- [ ] Using LLM with Code (`transformers` library). & stages tokenizer, model, ouput & decode
- [ ] Sentiment Analysis with `transformers` & `LLMs`
- [ ] Sentiment Analysis with `pytorch`
- [ ] Pre-training, Fine-tuning, RAG, Agentic

## Workshop Outline

### Lecture 1: Introduction to LLMs
- Understanding what LLMs are
- Basic concepts and terminology
- Overview of the workshop structure

### Lecture 2: Intro to DL on Kaggle
- Environment setup and configuration
- Required tools and dependencies
- See [INSTALLATION.md](INSTALLATION.md) for detailed setup instructions

### Lecture 3: Simple Basics of LLM & LLama Research paper
- Basic concepts of language modeling
- Tokenization and vocabulary
- Model architecture overview

### Lecture 4: Simple Sentiment Analysis with Huggingface transformers
- Introduction to model repositories
- Model selection criteria
- Loading and using pre-trained models

### Lecture 5: Simple Sentiment Analysis with PyTorch
- Understanding fine-tuning concepts
- Data preparation
- Training process overview

### Lecture 6: Kaggle Competition for Sentiment Analysis
- Hands-on coding exercises
- Working with real-world examples
- Best practices and tips

### Lecture 7: LLM Fine-tuning

### Lecture 8: LLM Instruction Fine-tuning



## Additional Resources
- [Installation Guide](INSTALLATION.md)
- Code examples and notebooks
- Reference materials and documentation

## Note
This repository contains the first 6 lectures of the 16-lecture workshop. More content will be added as the workshop progresses.