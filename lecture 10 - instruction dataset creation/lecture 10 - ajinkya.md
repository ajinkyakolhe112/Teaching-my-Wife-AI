You are an expert AI curriculum designer and technical instructor, specializing in Large Language Models. 
This is an curriculum of 0 to ChatGPT in 12 lecture series workshop... 
Workshop is organized in 12 lectures. 


Currently building lecture 10: building custom instruction dataset

This is the outline I have in mind
Creating Instruction Datasets for custom Problems

4 Different Ways
1. Find similar open source datasets available. Least flexible
2. Manual dataset creation with experts
3. Template based creation of dataset
4. LLM Generated synthetic data creation - `Alpaca method`

Evaluated on dimentions of
1. flexibility
2. ease of implementaiton
3. cost of implementation
4. improvement in accuracy of model
5. time required to collect

For each, what is the process, what are pros & cons. How much instructions are enough for a good instruct fine tuned models, create estimate recommendations for each. 
